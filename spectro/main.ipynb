{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7e50fb7-acc4-404a-a28b-8dcdf59b9a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 184\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;66;03m# Запуск\u001b[39;00m\n\u001b[0;32m    183\u001b[0m rt_spec \u001b[38;5;241m=\u001b[39m RealtimeSpectrogram()\n\u001b[1;32m--> 184\u001b[0m \u001b[43mrt_spec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 180\u001b[0m, in \u001b[0;36mRealtimeSpectrogram.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mani \u001b[38;5;241m=\u001b[39m FuncAnimation(\n\u001b[0;32m    173\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfig,\n\u001b[0;32m    174\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    177\u001b[0m     cache_frame_data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    178\u001b[0m )\n\u001b[0;32m    179\u001b[0m plt\u001b[38;5;241m.\u001b[39mtight_layout()\n\u001b[1;32m--> 180\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\matplotlib\\pyplot.py:612\u001b[0m, in \u001b[0;36mshow\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    568\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;124;03mDisplay all open figures.\u001b[39;00m\n\u001b[0;32m    570\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[38;5;124;03mexplicitly there.\u001b[39;00m\n\u001b[0;32m    610\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    611\u001b[0m _warn_if_gui_out_of_main_thread()\n\u001b[1;32m--> 612\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _get_backend_mod()\u001b[38;5;241m.\u001b[39mshow(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\matplotlib\\backend_bases.py:3553\u001b[0m, in \u001b[0;36m_Backend.show\u001b[1;34m(cls, block)\u001b[0m\n\u001b[0;32m   3551\u001b[0m     block \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m ipython_pylab \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_interactive()\n\u001b[0;32m   3552\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[1;32m-> 3553\u001b[0m     \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmainloop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\matplotlib\\backends\\backend_qt.py:633\u001b[0m, in \u001b[0;36mFigureManagerQT.start_main_loop\u001b[1;34m(cls)\u001b[0m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m qapp:\n\u001b[0;32m    632\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _allow_interrupt_qt(qapp):\n\u001b[1;32m--> 633\u001b[0m         qt_compat\u001b[38;5;241m.\u001b[39m_exec(qapp)\n",
      "File \u001b[1;32mC:\\Program Files\\Python39\\lib\\contextlib.py:126\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[1;34m(self, typ, value, traceback)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 126\u001b[0m         \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    127\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m    128\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\matplotlib\\backend_bases.py:1672\u001b[0m, in \u001b[0;36m_allow_interrupt\u001b[1;34m(prepare_notifier, handle_sigint)\u001b[0m\n\u001b[0;32m   1670\u001b[0m signal\u001b[38;5;241m.\u001b[39msignal(signal\u001b[38;5;241m.\u001b[39mSIGINT, old_sigint_handler)\n\u001b[0;32m   1671\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handler_args \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1672\u001b[0m     \u001b[43mold_sigint_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhandler_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sounddevice as sd\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import time\n",
    "import torch\n",
    "import torch.fft\n",
    "from collections import deque\n",
    "%matplotlib qt5\n",
    "\n",
    "# Конфигурация\n",
    "RT_CONFIG = {\n",
    "    'n_fft': 2048,  # Уменьшено для производительности\n",
    "    'hop_length': 256,\n",
    "    'sr': 44100,\n",
    "    'channels': 1,\n",
    "    'cmap': 'inferno',\n",
    "    'downsample': 4,\n",
    "    'db_range': 80,\n",
    "    'buffer_seconds': 2,\n",
    "    'window': 'hann',\n",
    "    'update_interval': 20,  # мс\n",
    "    'use_gpu': True  # Переключение GPU/CPU\n",
    "}\n",
    "\n",
    "class RealtimeSpectrogram:\n",
    "    def __init__(self):\n",
    "        # Инициализация буферов\n",
    "        self.audio_buffer = np.zeros(RT_CONFIG['sr'] * RT_CONFIG['buffer_seconds'], dtype=np.float32)\n",
    "        self.spec_buffer = deque(maxlen=1)  # Для хранения последнего спектра\n",
    "        self.time_buffer = deque()  # Для хранения временных меток\n",
    "        \n",
    "        # Размеры спектрограммы\n",
    "        self.freq_bins = (RT_CONFIG['n_fft'] // 2) // RT_CONFIG['downsample']\n",
    "        self.time_bins = int(RT_CONFIG['sr'] * RT_CONFIG['buffer_seconds'] / RT_CONFIG['hop_length'])\n",
    "        \n",
    "        # Инициализация спектрограммы\n",
    "        self.spectrogram = np.full((self.freq_bins, self.time_bins), -RT_CONFIG['db_range'], dtype=np.float32)\n",
    "        \n",
    "        # Настройка GPU\n",
    "        self.use_gpu = RT_CONFIG['use_gpu'] and torch.cuda.is_available()\n",
    "        self.device = torch.device('cuda' if self.use_gpu else 'cpu')\n",
    "        print(f\"Using {'GPU' if self.use_gpu else 'CPU'}\")\n",
    "        \n",
    "        if self.use_gpu:\n",
    "            # Создаем окно на GPU\n",
    "            self.window = torch.hann_window(RT_CONFIG['n_fft'], device=self.device)\n",
    "        \n",
    "        # Создаем фигуру\n",
    "        self.fig, self.ax = plt.subplots(figsize=(12, 6))\n",
    "        max_freq = RT_CONFIG['sr'] // 2\n",
    "        self.img = self.ax.imshow(\n",
    "            self.spectrogram,\n",
    "            aspect='auto',\n",
    "            origin='lower',\n",
    "            cmap=RT_CONFIG['cmap'],\n",
    "            extent=[0, RT_CONFIG['buffer_seconds'], 0, max_freq],\n",
    "            vmin=-RT_CONFIG['db_range'],\n",
    "            vmax=0\n",
    "        )\n",
    "        self.ax.set_xlabel('Time (s)')\n",
    "        self.ax.set_ylabel('Frequency (Hz)')\n",
    "        cbar = self.fig.colorbar(self.img, format='%+2.0f dB')\n",
    "        cbar.set_label('dB Relative Scale')\n",
    "        \n",
    "        # Настройки темного фона\n",
    "        self.fig.patch.set_facecolor('#000000')\n",
    "        self.ax.set_facecolor('#000000')\n",
    "        self.ax.tick_params(colors='white')\n",
    "        self.ax.xaxis.label.set_color('white')\n",
    "        self.ax.yaxis.label.set_color('white')\n",
    "        \n",
    "        # Статистика производительности\n",
    "        self.frame_count = 0\n",
    "        self.last_fps_time = time.time()\n",
    "        self.processing_times = []\n",
    "        \n",
    "        # Поток аудио\n",
    "        self.stream = sd.InputStream(\n",
    "            callback=self.audio_callback,\n",
    "            channels=RT_CONFIG['channels'],\n",
    "            samplerate=RT_CONFIG['sr'],\n",
    "            blocksize=RT_CONFIG['hop_length'],\n",
    "            dtype=np.float32\n",
    "        )\n",
    "    \n",
    "    def audio_callback(self, indata, frames, time_info, status):\n",
    "        # Добавляем новые данные в буфер\n",
    "        self.audio_buffer = np.roll(self.audio_buffer, -frames)\n",
    "        self.audio_buffer[-frames:] = indata[:, 0]\n",
    "        \n",
    "        # Обрабатываем данные сразу\n",
    "        self.process_audio()\n",
    "    \n",
    "    def process_audio(self):\n",
    "        \"\"\"Обработка аудио и вычисление спектра\"\"\"\n",
    "        # Берем последние n_fft сэмплов\n",
    "        start_idx = -RT_CONFIG['n_fft']\n",
    "        segment = self.audio_buffer[start_idx:] if start_idx < 0 else np.zeros(RT_CONFIG['n_fft'])\n",
    "        \n",
    "        # Обработка на GPU\n",
    "        if self.use_gpu:\n",
    "            segment_tensor = torch.tensor(segment, device=self.device, dtype=torch.float32)\n",
    "            windowed = segment_tensor * self.window\n",
    "            stft = torch.fft.rfft(windowed)\n",
    "            magnitude = torch.abs(stft)\n",
    "            db = 20 * torch.log10(torch.clamp(magnitude, min=1e-10))\n",
    "            db = torch.clamp(db, min=-RT_CONFIG['db_range'], max=0)\n",
    "            db = db[::RT_CONFIG['downsample']].cpu().numpy()\n",
    "        \n",
    "        # Обработка на CPU\n",
    "        else:\n",
    "            window = np.hanning(RT_CONFIG['n_fft'])\n",
    "            windowed = segment * window\n",
    "            stft = np.fft.rfft(windowed)\n",
    "            magnitude = np.abs(stft)\n",
    "            db = 20 * np.log10(np.maximum(magnitude, 1e-10))\n",
    "            db = np.clip(db, -RT_CONFIG['db_range'], 0)\n",
    "            db = db[::RT_CONFIG['downsample']]\n",
    "        \n",
    "        # Сохраняем результат с временной меткой\n",
    "        timestamp = time.time()\n",
    "        self.spec_buffer.append(db)\n",
    "        self.time_buffer.append(timestamp)\n",
    "    \n",
    "    def update(self, frame):\n",
    "        start_time = time.perf_counter()\n",
    "        \n",
    "        # Обновляем спектрограмму только при наличии новых данных\n",
    "        if not self.spec_buffer:\n",
    "            return [self.img]\n",
    "        \n",
    "        # Берем последний спектр\n",
    "        db = self.spec_buffer.popleft()\n",
    "        timestamp = self.time_buffer.popleft()\n",
    "        \n",
    "        # Удаляем устаревшие данные\n",
    "        current_time = time.time()\n",
    "        max_age = RT_CONFIG['buffer_seconds']\n",
    "        \n",
    "        # Обновляем спектрограмму\n",
    "        self.spectrogram = np.roll(self.spectrogram, -1, axis=1)\n",
    "        \n",
    "        # Вставляем новые данные\n",
    "        valid_bins = min(db.shape[0], self.spectrogram.shape[0])\n",
    "        self.spectrogram[:valid_bins, -1] = db[:valid_bins]\n",
    "        \n",
    "        # Заполняем остаток минимальным значени\n",
    "        if valid_bins < self.spectrogram.shape[0]:\n",
    "            self.spectrogram[valid_bins:, -1] = -RT_CONFIG['db_range']\n",
    "        \n",
    "        self.img.set_data(self.spectrogram)\n",
    "        \n",
    "        self.frame_count += 1\n",
    "        processing_time = time.perf_counter() - start_time\n",
    "        self.processing_times.append(processing_time)\n",
    "        \n",
    "        current_time = time.time()\n",
    "        if current_time - self.last_fps_time >= 1.0:\n",
    "            fps = self.frame_count / (current_time - self.last_fps_time)\n",
    "            avg_time = np.mean(self.processing_times) * 1000 if self.processing_times else 0\n",
    "            self.frame_count = 0\n",
    "            self.last_fps_time = current_time\n",
    "            self.processing_times = []\n",
    "        \n",
    "        return [self.img]\n",
    "    \n",
    "    def start(self):\n",
    "        self.stream.start()\n",
    "        self.last_fps_time = time.time()\n",
    "        \n",
    "        self.ani = FuncAnimation(\n",
    "            self.fig,\n",
    "            self.update,\n",
    "            interval=RT_CONFIG['update_interval'],\n",
    "            blit=True,\n",
    "            cache_frame_data=False\n",
    "        )\n",
    "        plt.tight_layout()\n",
    "        plt.show(block=True)\n",
    "\n",
    "# Запуск\n",
    "rt_spec = RealtimeSpectrogram()\n",
    "rt_spec.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2048f269-b992-49c8-932f-0ea54ec89078",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
